{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217b3623",
   "metadata": {},
   "source": [
    "# Zumi Obstacle Classification\n",
    "\n",
    "**Overview:** Train Zumi with 'soft toy' and 'plastic cup' using the k-NN algorithm and compare this model to a Logistic Regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8142db8",
   "metadata": {},
   "source": [
    "## 1.Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa0a25",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "The `calculate_sum` function returns the sum of the front_left and front_right sensor readings. This function is called in the `collect_data` function and the front infared sensors are passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38245380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sum.\n",
    "def calculate_sum(front_left, front_right):\n",
    "    \n",
    "    # Calculate sum of front_left and front_right sensors\n",
    "    result = front_left + front_right\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bab218",
   "metadata": {},
   "source": [
    "#### Feature engineering - code details\n",
    "\n",
    "* *def calculate_sum(front_left, front_right)* : `calculate_sum` is the function name which recieves the front_left and front_right sensor readings as arguments.\n",
    "* *result = front_left + front_right* : The `result` variable stores the value of the front_left and front_right sensor readings.\n",
    "* *return result* : The `result` variable is returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zumi.zumi import Zumi\n",
    "from zumi.util.screen import Screen\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "zumi = Zumi()\n",
    "screen = Screen()\n",
    "        \n",
    "IR_FRONT_RIGHT = 0\n",
    "IR_FRONT_LEFT = 5\n",
    "\n",
    "DATA_WITH_NOISE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf771f2",
   "metadata": {},
   "source": [
    "### Data Collection - *collect data without noise*\n",
    "\n",
    "The `collect_data` function has been implemented two different ways for collecting data.\n",
    "\n",
    "This was done so that you have the option of running the application and collect data without noise added to the data points or with noise added.\n",
    "\n",
    "* If you want to add noise to the sensor readings, **do not run the cell block below**. Instead, run the cell block under `Data Augmentation`.\n",
    "\n",
    "* If you *do not want noise added to the data*, then run the cell below, but do not run the `Data Augmentation` code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Try loading previous data, if exists. Otherwise, start with an empty list.\n",
    "# This will store our sensor readings and labels.\n",
    "try:\n",
    "    with open('zumi_data.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "        data = [] # This will store our sensor readings and labels.\n",
    "\n",
    "# Function to collect data.\n",
    "def collect_data(obstacle_label):\n",
    "    # Read from front infrared sensors.\n",
    "    front_left = zumi.get_IR_data(IR_FRONT_LEFT)\n",
    "    front_right = zumi.get_IR_data(IR_FRONT_RIGHT)\n",
    "    \n",
    "    # Call calculate_sum function\n",
    "    ir_sum = calculate_sum(front_left, front_right)\n",
    "\n",
    "    # Create a dictionary for each data point and then append it to the data list\n",
    "    # In addition, add the sum as a new feature for each data point\n",
    "    data_point = {'front_left': front_left, 'front_right': front_right, 'sum': ir_sum, 'label': obstacle_label}\n",
    "    data.append(data_point)\n",
    "    \n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9962660",
   "metadata": {},
   "source": [
    "#### Collecting data - code changes\n",
    "\n",
    "* *sum = calculate_sum(front_left, front_right)* : Calculates the sum of each data point by passing the left and right sensor readings as arugments to the `calculate_sum` function. This value is returned and stored in the `ir_sum` variable.\n",
    "* *data_point = {'front_left': front_left, 'front_right': front_right, 'sum': ir_sum, 'label': obstacle_label}* : The sum is added as a new feature to the data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81161628",
   "metadata": {},
   "source": [
    "### Data Augmentation - *collect data with noise*\n",
    "\n",
    "**Run the cell block below if you want to run the application using noise added to the sensor readings**; do not run the code block above.\n",
    "\n",
    "The function `add_gaussian_noise` adds noise to a single sensor reading. We call this function in the `collect_data` function and pass the front_left and front_right sensor reading values as arguments.\n",
    "\n",
    "     Args:\n",
    "        - sensor_value: Single sensor reading value.\n",
    "        - mean: Mean of the Gaussian distribution (default: 0).\n",
    "        - std_dev: Standard deviation of the Gaussian distribution (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        - Sensor reading value with added Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964da6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Try loading previous data, if exists. Otherwise, start with an empty list.\n",
    "# This will store our sensor readings and labels.\n",
    "try:\n",
    "    with open('zumi_data_noise.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "        data = [] # This will store our sensor readings and labels.\n",
    "\n",
    "# Function to add Gaussian noise to sensor readings\n",
    "def add_gaussian_noise(sensor_value, mean=0, std_dev=0.1):\n",
    "    \n",
    "    # Set data noise variable to True\n",
    "    DATA_WITH_NOISE = True\n",
    "    \n",
    "    noise = np.random.normal(mean, std_dev)\n",
    "    noisy_sensor_value = sensor_value + noise\n",
    "    return noisy_sensor_value\n",
    "\n",
    "# Function to collect data with added Gaussian noise\n",
    "def collect_data(obstacle_label):\n",
    "    # Read from front infrared sensors.\n",
    "    front_left = zumi.get_IR_data(IR_FRONT_LEFT)\n",
    "    front_right = zumi.get_IR_data(IR_FRONT_RIGHT)\n",
    "    \n",
    "    # Adding Gaussian noise to the sensor readings\n",
    "    noisy_front_left = add_gaussian_noise(front_left)\n",
    "    noisy_front_right = add_gaussian_noise(front_right)\n",
    "\n",
    "    # Call calculate_sum function\n",
    "    ir_sum = calculate_sum(noisy_front_left, noisy_front_right)\n",
    "\n",
    "    # Create a dictionary for each data point and then append it to the data list\n",
    "    # In addition, add the sum as a new feature for each data point\n",
    "    data_point = {'front_left': noisy_front_left, 'front_right': noisy_front_right, 'sum': ir_sum, 'label': obstacle_label}\n",
    "    data.append(data_point)\n",
    "    \n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ad220",
   "metadata": {},
   "source": [
    "To collect data, manually drive Zumi near each obstacle and execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09cf728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting multiple readings for soft toy.\n",
    "print(\"Drive Zumi near the soft toy and press Enter...\")\n",
    "for _ in range(5):  # Change this number if you want to collect more or fewer readings.\n",
    "    input()\n",
    "    collect_data('soft toy')\n",
    "    print(\"Collected data for soft toy. Continue or move to the next position.\")\n",
    "    \n",
    "# Collecting multiple readings for plastic cup.\n",
    "print(\"\\nDrive Zumi near the plastic cup and press Enter...\")\n",
    "for _ in range(5):  # Change this number if you want to collect more or fewer readings.\n",
    "    input()\n",
    "    collect_data('plastic cup')\n",
    "    print(\"Collected data for plastic cup. Continue or move to the next position.\")\n",
    "\n",
    "# Saving the updated data for future use.\n",
    "if (DATA_WITH_NOISE):\n",
    "    with open('zumi_data_noise.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "else:\n",
    "    with open('zumi_data.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "print(\"\\nData collection complete and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada6339",
   "metadata": {},
   "source": [
    "## 2. Storing & Visualizing Data\n",
    "Print a table of the data colleced by Zumi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data in a tabular format\n",
    "print(\"\\nCollected Data:\")\n",
    "\n",
    "# Print header\n",
    "print(\"front_left\", \"front_right\", \"sum\", \"label\")\n",
    "\n",
    "# Print data\n",
    "for row in data:\n",
    "    print(row['front_left'], row['front_right'], row['sum'], row['label'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1744b",
   "metadata": {},
   "source": [
    "## 3. Plotting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd6632",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "Plot a 2D graph and 3D graph of the data points collected by Zumi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# We will create a dictionary to hold our groups\n",
    "grouped_data = {}\n",
    "\n",
    "# Define markers and colors for each label\n",
    "markers = ['o', 's', '^', '<', '>', 's', '*', 'D']\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black'] \n",
    "# Iterate over the data to populate the dictionary\n",
    "for idx, row in enumerate(data):\n",
    "    label = row['label']\n",
    "    if label not in grouped_data:\n",
    "        grouped_data[label] = {'front_left': [], 'front_right': [], 'marker': random.choice(markers), 'color': random.choice(colors)}\n",
    "    grouped_data[label]['front_left'].append(row['front_left'])\n",
    "    grouped_data[label]['front_right'].append(row['front_right'])\n",
    "\n",
    "# Now we have a dictionary with lists of data points for each label\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, group in grouped_data.items():\n",
    "    ax.scatter(group['front_left'], group['front_right'], marker=group['marker'], color=group['color'], label=label)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Front Left IR Value')\n",
    "plt.ylabel('Front Right IR Value')\n",
    "plt.title('IR Sensor Readings for Different Obstacles')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde85561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting functionality\n",
    "import random\n",
    "\n",
    "# Create a dictionary to hold our groups\n",
    "grouped_data = {}\n",
    "\n",
    "# Define markers and colors for each label\n",
    "markers = ['o', 's', '^', '<', '>', 's', '*', 'D']  # You can extend this list with more markers if needed\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']  # You can add more colors or use different color palettes\n",
    "\n",
    "# Iterate over the data to populate the dictionary\n",
    "for idx, row in enumerate(data):\n",
    "    label = row['label']\n",
    "    if label not in grouped_data:\n",
    "        grouped_data[label] = {'front_left': [], 'front_right': [], 'sum': [], 'marker': random.choice(markers), 'color': random.choice(colors)}\n",
    "    grouped_data[label]['front_left'].append(row['front_left'])\n",
    "    grouped_data[label]['front_right'].append(row['front_right'])\n",
    "    grouped_data[label]['sum'].append(row['sum'])\n",
    "\n",
    "# Now we have a dictionary with lists of data points for each label, including the 'sum' feature\n",
    "\n",
    "# Plotting in 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for label, group in grouped_data.items():\n",
    "    ax.scatter(group['front_left'], group['front_right'], group['sum'], marker=group['marker'], color=group['color'], label=label)\n",
    "\n",
    "ax.set_xlabel('Front Left IR Value')\n",
    "ax.set_ylabel('Front Right IR Value')\n",
    "ax.set_zlabel('Sum of Sensor Readings')\n",
    "ax.set_title('3D Scatter Plot of IR Sensor Readings')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f13c65",
   "metadata": {},
   "source": [
    "#### 3. Plotting Data - Details\n",
    "**Graph 1:** Plot the data on a 2D graph.\n",
    "* *markers = ['o', 's', '^', '<', '>', 's', \"\", 'D']* : Define a list of markers.\n",
    "* *colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']* : Define a list of colors.\n",
    "* *'marker': random.choice(markers), 'color': random.choice(colors)* : Randomly choose a marker and color from the defined list to represent each label.\n",
    "\n",
    "**Graph 2:** Plot the data on a 3D graph\n",
    "* The same marker and color code implementation from 2D graph is used.\n",
    "* *grouped_data[label] = {'front_left': [], 'front_right': [], 'sum': []* : Create a third feature label (sum).\n",
    "* *grouped_data[label]['sum'].append(row['sum'])* : Add the third feature data to the `grouped_data` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e4ead",
   "metadata": {},
   "source": [
    "## 4. Implementing & Training k-NN and Logistic Regression\n",
    "Split the data and train our k-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dceec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into training and test sets.\n",
    "\n",
    "X = [[row['front_left'], row['front_right'], row['sum']] for row in data]\n",
    "y = [row['label'] for row in data]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "k = 3  # For simplicity, we'll start with k=3.\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the classifier.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Print out classification report\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec1e3a",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Train a `LogisticRegression` model and compare results to the k-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LogisticRegression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "# Split data\n",
    "X_log = [[row['front_left'], row['front_right'], row['sum']] for row in data]\n",
    "y_log = [row['label'] for row in data]\n",
    "\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "# Train LogisticRegression model\n",
    "logreg = LogisticRegression(C=0.1)\n",
    "logreg.fit(X_train_log, y_train_log)\n",
    "   \n",
    "pred_logreg = logreg.predict(X_test_log)\n",
    "    \n",
    "# Print out classification report\n",
    "print('Logistic Regression Model')\n",
    "print(classification_report(y_test_log, pred_logreg))\n",
    "    \n",
    "# Print prediction score\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test_log, y_test_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3ff2c",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Train the k-NN classifier with different values of `k` to determine the best value for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6155080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of k values to try\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "# Dictionary to store accuracy scores for different k values\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Iterate over each k value\n",
    "for k in k_values:\n",
    "    # Initialize k-NN classifier with the current k value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the classifier\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and store it in the dictionary\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores[k] = accuracy\n",
    "    print(\"k = {}, Accuracy = {}\".format(k, accuracy))\n",
    "\n",
    "# Find the best k value based on accuracy\n",
    "best_k = max(accuracy_scores, key=accuracy_scores.get)\n",
    "best_accuracy = accuracy_scores[best_k]\n",
    "\n",
    "print(\"\\nBest k value: {} with accuracy: {}\".format(best_k, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a0dde",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - Details\n",
    "* *k_values = [1, 3, 5, 7, 9, 11, 13, 15]* : Create a list of k_values.\n",
    "* *accuracy_scores = {}* : Dictionary to store accuracy scores for different k values.\n",
    "* *for k in k_values* : A for loop to iterate over each k value and assign it to the K-NN classifier. Calculate the accuracy and store it in the dictionary.\n",
    "* *best_k = max(accuracy_scores, key=accuracy_scores.get)* : Find the best k value based on accuracy.\n",
    "* *print(\"\\nBest k value: {} with accuracy: {}\".format(best_k, best_accuracy))* : Print the best k value and its' accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d15455",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Generate a confusion matrix for the k-NN and Logistic Regression classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "# Generate a confusion matrix for k-NN classifier\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"K-NN confusion matrix:\\n{}\".format(confusion))\n",
    "    \n",
    "# Generate a confusion matrix for LogisticRegression classifier\n",
    "confusion_log = confusion_matrix(y_test_log, pred_logreg)\n",
    "print(\"Logistic Regression confusion matrix:\\n{}\".format(confusion_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68604701",
   "metadata": {},
   "source": [
    "### Cross-Validation with cross_val_score\n",
    "Implement k-fold cross-validation using the `cross_val_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# K-NN Model\n",
    "# you can change the number of folds using the \"cv\" parameter\n",
    "knn_scores = cross_val_score(knn, X, y, cv=5)\n",
    "print(\"K-NN cross-validation scores: {}\".format(knn_scores))\n",
    "# to summarize the cross-validation, compute the mean:\n",
    "print(\"K-NN average cross-validation score: {:.2f}\".format(knn_scores.mean()))\n",
    "\n",
    "# Logistic Regression Model\n",
    "logreg_scores = cross_val_score(logreg, X_log, y_log, cv=5)\n",
    "print(\"Logistic Regression cross-validation scores: {}\".format(logreg_scores))\n",
    "# to summarize the cross-validation, compute the mean:\n",
    "print(\"Logistic Regression average cross-validation score: {:.2f}\".format(logreg_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769de85",
   "metadata": {},
   "source": [
    "## 5. Real-time Decision Making\n",
    "Instruct Zumi to react differently based on the obstacle type using the `react_to_obstacle` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zumi.personality import Personality\n",
    "\n",
    "def react_to_obstacle(type):\n",
    "    \n",
    "    personality = Personality(zumi, screen)\n",
    "    \n",
    "    if (type == 'soft toy'):\n",
    "        zumi.headlights_on()\n",
    "        personality.happy()\n",
    "        time.sleep(2)\n",
    "        zumi.all_lights_off()\n",
    "    elif (type == 'plastic cup'):\n",
    "        zumi.circle_right(speed=60, step=10)\n",
    "        personality.look_around()\n",
    "        zumi.circle_left(speed=60, step=10)\n",
    "    else:\n",
    "        zumi.all_lights_on()\n",
    "        time.sleep(3)\n",
    "        zumi.all_lights_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ebad14",
   "metadata": {},
   "source": [
    "#### `react_to_obstacle` - Details\n",
    "* *from zumi.personality import Personality* : Import Personality module from Zumi.\n",
    "* *if (type == 'soft toy')* : If the obstacle type is a `soft toy`, then the following code block executes.\n",
    "* *zumi.headlights_on()* : Turn Zumi's headlights on.\n",
    "* *personality.happy()* : Change Zumi's personality to 'happy'.\n",
    "* *time.sleep(2)* : Wait 2 seconds.\n",
    "* *zumi.all_lights_off()* : Turn Zumi's headlights off.\n",
    "* *elif (type == 'plastic cup')* : If the obstacle type is a `plastic cup`, then the following code block executes.\n",
    "* *zumi.circle_right(speed=60, step=10)* : Circle Zumi to the right at a speed of 60 and a step of 10.\n",
    "* *personality.look_around()* : Change Zumi's personality to look around.\n",
    "* *zumi.circle_left(speed=60, step=10)* : Circle Zumi to the left at a speed of 60 and a step of 10.\n",
    "* *else* : If the obstacle type is **neither** a `soft toy` or `plastic cup`, then the following code block executes.\n",
    "* *zumi.all_lights_on()* : Turn on all of Zumi's lights.\n",
    "* *time.sleep(3)* : Wait 3 seconds.\n",
    "* *zumi.all_lights_off()* Turn off all of Zumi's lights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7faf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_obstacle():\n",
    "    # Read from front infrared sensors.\n",
    "    front_left = zumi.get_IR_data(IR_FRONT_LEFT)\n",
    "    front_right = zumi.get_IR_data(IR_FRONT_RIGHT)\n",
    "    \n",
    "    ir_sum = calculate_sum(front_left, front_right)\n",
    "    \n",
    "    prediction = knn.predict([[front_left, front_right, ir_sum]])\n",
    "    \n",
    "    # Display the prediction on Zumi's screen\n",
    "    screen.draw_text(\"Pred: \" + str(prediction[0]))\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "print(\"Classifying obstacle...\")\n",
    "obstacle_type = classify_obstacle()\n",
    "# Call the 'react_to_obstacle' function\n",
    "react_to_obstacle(obstacle_type)\n",
    "obstacle_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f791f3",
   "metadata": {},
   "source": [
    "#### `classify_obstacle` - Code changes & details\n",
    "* *ir_sum = calculate_sum(front_left, front_right)* : Calculate the sum of the infared sensor readings.\n",
    "* *prediction = knn.predict([[front_left, front_right, ir_sum]])* : Provide the front sensor readings and the sum to the predict method of the classifier.\n",
    "* *react_to_obstacle(obstacle_type)* : Pass the obstacle type to the `react_to_obstacle` function. Watch as Zumi reacts to the predicted obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e2813",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "Check the accuracy of the k-NN and Logistic Regression classifiers using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_k = accuracy_score(y_test, y_pred)\n",
    "print(\"K-NN accuracy: {}\".format(accuracy_k))\n",
    "\n",
    "y_pred_log = logreg.predict(X_test_log)\n",
    "accuracy_log = accuracy_score(y_test_log, y_pred_log)\n",
    "print(\"Logistic Regression accuracy: {}\".format(accuracy_log))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
